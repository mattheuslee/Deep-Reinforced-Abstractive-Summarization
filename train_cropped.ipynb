{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nltk\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from tqdm import tqdm, trange, tnrange, tqdm_notebook\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "from model import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize = nltk.word_tokenize, use_vocab = True, init_token = \"<s>\", eos_token = \"<e>\", lower = True, include_lengths = True, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training stories\n",
      "Loading testing stories\n",
      "Loading validation stories\n",
      "Building vocabulary\n",
      "Vocabulary size: 82850\n"
     ]
    }
   ],
   "source": [
    "tqdm.write(\"Loading training stories\")\n",
    "train = TabularDataset(path = \"cnn_stories_cropped_train.txt\",\n",
    "                       format = 'tsv',\n",
    "                       fields = [('input', TEXT), ('target', TEXT)])\n",
    "tqdm.write(\"Loading testing stories\")\n",
    "test  = TabularDataset(path = \"cnn_stories_cropped_test.txt\",\n",
    "                       format = 'tsv',\n",
    "                       fields = [('input', TEXT), ('target', TEXT)])\n",
    "tqdm.write(\"Loading validation stories\")\n",
    "valid = TabularDataset(path = \"cnn_stories_cropped_valid.txt\",\n",
    "                       format = 'tsv',\n",
    "                       fields = [('input', TEXT), ('target', TEXT)])\n",
    "tqdm.write(\"Building vocabulary\")\n",
    "TEXT.build_vocab(train, test, valid, min_freq = 2)\n",
    "tqdm.write(\"Vocabulary size: {}\".format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training stories: 73972\n",
      "Number of testing stories: 14794\n",
      "Number of validation stories: 3699\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_loader = BucketIterator(train,batch_size=BATCH_SIZE, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "test_loader  = BucketIterator(test,batch_size=BATCH_SIZE, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "valid_loader = BucketIterator(valid,batch_size=1, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "tqdm.write(\"Number of training stories: {}\".format(len(train)))\n",
    "tqdm.write(\"Number of testing stories: {}\".format(len(test)))\n",
    "tqdm.write(\"Number of validation stories: {}\".format(len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 50\n",
    "EMBED_SIZE  = 300\n",
    "VOCAB_SIZE  = len(TEXT.vocab)\n",
    "LEARN_RATE  = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, bidirec=True)\n",
    "decoder = Decoder(VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    encoder.load_state_dict(torch.load(\"./encoder.model\"))\n",
    "    decoder.load_state_dict(torch.load(\"./decoder.model\"))\n",
    "#load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models():\n",
    "    torch.save(encoder.state_dict(), \"./encoder.model\")\n",
    "    torch.save(decoder.state_dict(), \"./decoder.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = True\n",
    "if USE_CUDA:\n",
    "    tqdm.write(\"Using CUDA\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using %d devices\" % (torch.cuda.device_count()))\n",
    "        encoder = nn.DataParallel(encoder)\n",
    "        decoder = nn.DataParallel(decoder)\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "decoder.embedding = encoder.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index = TEXT.vocab.stoi['<pad>'])\n",
    "enc_optim = optim.Adam(encoder.parameters(), lr = LEARN_RATE)\n",
    "dec_optim = optim.Adam(decoder.parameters(), lr = LEARN_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136a8fccc5104819a465f72b1f4214ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Epochs', max=10), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16ff2fa12e248e7825badebc111dee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Batches', max=9247), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_EPOCHS          = 10\n",
    "EPOCH_SAVE_INTERVAL = 1\n",
    "for epoch_idx in tnrange(NUM_EPOCHS, desc = \"Epochs\", unit = \"epoch\"):\n",
    "    encoder = encoder.train()\n",
    "    decoder = decoder.train()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(train_loader, desc = \"Batches\", unit = \"batch\"):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "        loss.backward()\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "    train_loss_mean = total_loss / num_batches\n",
    "    train_loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    \n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(test_loader, desc = \"Batches\", unit = \"batch\"):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"%3d Training --- loss mean: %7.4f, loss variance: %7.4f\" % (epoch_idx + 1, train_loss_mean, train_loss_variance))\n",
    "    tqdm.write(\"     Testing --- loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))\n",
    "    \n",
    "    if (epoch_idx + 1) % EPOCH_SAVE_INTERVAL == 0:\n",
    "        save_models()\n",
    "        \n",
    "save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import ROUGE\n",
    "from __future__ import print_function\n",
    "rouge = ROUGE()\n",
    "\n",
    "def get_string(summary):\n",
    "    result = \"\"\n",
    "    for idx in summary:\n",
    "        if idx == TEXT.vocab.stoi[\"unk\"]:\n",
    "            continue\n",
    "        elif idx in [TEXT.vocab.stoi[\"pad\"], TEXT.vocab.stoi[\"<e>\"]]:\n",
    "            break\n",
    "        result += TEXT.vocab.itos[idx] + \" \"\n",
    "        \n",
    "    return result\n",
    "\n",
    "def show_selection_of_output(loader, num_to_show, num_to_calculate):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    total_rouge_score = {\"rouge-1\": {\"recall\": 0.0, \"precision\": 0.0},\n",
    "                         \"rouge-2\": {\"recall\": 0.0, \"precision\": 0.0}}\n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i == num_to_calculate:\n",
    "            break\n",
    "        inputs, lengths = batch.input\n",
    "        targets, _ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        reference_summary = targets.data.cpu().numpy()[0]\n",
    "        generated_summary = [np.argmax(word) for word in score.data.cpu().numpy()[0]]\n",
    "\n",
    "        reference = get_string(reference_summary)\n",
    "        generated = get_string(generated_summary)\n",
    "\n",
    "        rouge_score = rouge.score(reference, generated)\n",
    "        \n",
    "        total_rouge_score[\"rouge-1\"][\"recall\"] += rouge_score[\"rouge-1\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-1\"][\"precision\"] += rouge_score[\"rouge-1\"][\"precision\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"recall\"] += rouge_score[\"rouge-2\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"precision\"] += rouge_score[\"rouge-2\"][\"precision\"]\n",
    "\n",
    "        if i < num_to_show:\n",
    "            print(\"\\nReference summary:\\n{}\".format(reference))\n",
    "            print(\"\\nGenerated summary:\\n{}\".format(generated))\n",
    "            print(\"\\nROUGE score: {}\\n\".format(rouge_score))\n",
    "        \n",
    "    total_rouge_score[\"rouge-1\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-1\"][\"precision\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"precision\"] /= num_to_show\n",
    "    print(\"Mean ROUGE score: {}\\n\".format(total_rouge_score))\n",
    "    encoder = encoder.train()\n",
    "    decoder = decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection of training stories\n",
      "\n",
      "Reference summary:\n",
      "<s> north korea plans to erect a statue of kim jong il and build towers across the country \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-2': {'recall': 0.0, 'precision': 0.0}, 'rouge-1': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> the bill would fight counterfeiting and piracy \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-2': {'recall': 0.0, 'precision': 0.0}, 'rouge-1': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> ferrari aiming for perfection after errors in malaysian and bahrain grands prix \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-2': {'recall': 0.0, 'precision': 0.0}, 'rouge-1': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> new : al-jazeera broadcast says tape in bin laden saying , ` iraq is perfect base ' \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-2': {'recall': 0.0, 'precision': 0.0}, 'rouge-1': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> the `` myspace shot `` makes you look like you have no friends \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-2': {'recall': 0.0, 'precision': 0.0}, 'rouge-1': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "Mean ROUGE score: {'rouge-2': {'recall': 0.0, 'precision': 0.0}, 'rouge-1': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Selection of training stories\")\n",
    "show_selection_of_output(train_loader, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selection of testing stories\")\n",
    "show_selection_of_output(test_loader, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selection of validation stories\")\n",
    "show_selection_of_output(valid_loader, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: <s> april 23 , 2014 this wednesday , we cover subjects related to civics , science and animal behavior . our first two reports center on supreme court cases , and our third examines the challenges still facing search crews more than a month after a massive landslide in washington state . we also explore the lingering effects of a 2010 oil spill and show you how some people are recovering from that . on this page you will find today 's show transcript , the daily curriculum , and a place for you to leave feedback . transcript click here <e>\n",
      "Target summary: <s> this page includes the show transcript and the daily curriculum \n",
      "Best sequence: <s> translatable wilhite fourth-placed vanover banderas nll hadnot constrain fitzwilliams cheated\n",
      "Top candidates:\n",
      "\t<s> translatable wilhite fourth-placed vanover banderas nll hadnot constrain fitzwilliams pursuant\n",
      "\t<s> translatable wilhite fourth-placed vanover banderas nll hadnot constrain fitzwilliams deflected\n",
      "\t<s> translatable wilhite fourth-placed vanover banderas nll hadnot constrain fitzwilliams alumbaugh\n",
      "\t<s> translatable wilhite fourth-placed vanover banderas nll hadnot constrain fitzwilliams jaggi\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "beam.py:93: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  scores = nn.Softmax()(scores)\n"
     ]
    }
   ],
   "source": [
    "from beam import BeamSearch\n",
    "beam_search = BeamSearch()\n",
    "\n",
    "BEAM_WIDTH  = 5\n",
    "BEAM_DEPTH  = 10\n",
    "NUM_TO_SHOW = 3\n",
    "\n",
    "for i, batch in enumerate(valid_loader):\n",
    "    if i == NUM_TO_SHOW:\n",
    "        break\n",
    "    inputs, lengths = batch.input\n",
    "    targets, _ = batch.target\n",
    "    if USE_CUDA:\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "    outputs, hidden = encoder(inputs, lengths.tolist())\n",
    "    cell = decoder.init_context(inputs.size(0))\n",
    "    \n",
    "    best_sequence, top_candidates = beam_search.get_words(hidden, cell, TEXT.vocab.stoi[\"<s>\"], outputs, lengths, decoder, TEXT.vocab, BEAM_WIDTH, BEAM_DEPTH)\n",
    "    \n",
    "    \n",
    "    target_summary = get_string(targets.data.cpu().numpy()[0])\n",
    "        \n",
    "    print(\"Article: {}\".format(\" \".join([TEXT.vocab.itos[idx] for idx in inputs.cpu().data[0]])))\n",
    "    print(\"Target summary: {}\".format(target_summary))\n",
    "    print(\"Best sequence: {}\".format(\" \".join(best_sequence)))\n",
    "    print(\"Top candidates:\")\n",
    "    for candidate in top_candidates[1:]:\n",
    "        print(\"\\t{}\".format(\" \".join(candidate)))\n",
    "    print(\"\\n\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
